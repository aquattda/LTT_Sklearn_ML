{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7646d568",
   "metadata": {},
   "source": [
    "# TÌM HIỂU TẤT CẢ CÁC THUẬT TOÁN MACHINE LEARING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c266d4d",
   "metadata": {},
   "source": [
    "## I.\tSupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2f7c4",
   "metadata": {},
   "source": [
    "### 1.\tLinear Regression (Hồi quy tuyến tính)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3a45e",
   "metadata": {},
   "source": [
    "-\tĐây là thuật toán tìm ra mối quan hệ tuyến tính tồn tại $1$-$N$ input **X** và output **Y**.\n",
    "-\tMối quan hệ tuyến tính là mối quan hệ bậc 1 ($y = ax + b$) giữa 2 biến **X**, **Y**.  </br>\n",
    "⟶ Dựa vào đó để đưa ra kết quả **Y** dựa vào đầu vào **X**. </br>\n",
    "⟶ Trong đó **X** là **Independent Variable** (**Feature**) và **Y** là **Dependent Variable** (**Target**). </br>\n",
    "\n",
    "⇒ Nếu tồn tại duy nhất một input $X$ (**Simple Linear Regression**): Dự đoán mức lương của một nhân viên dựa vào số năm kinh nghiệm của nhân viên đó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa530b6",
   "metadata": {},
   "source": [
    "![alt text](https://raw.githubusercontent.com/aquattda/LTT_Sklearn_ML/blob/main/images/Simple_Linear.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90054ea3",
   "metadata": {},
   "source": [
    "**Trong đó:**\n",
    "-\tA (**Intercept/Bias**): giá trị kỳ vọng của y hay gọi chung là giá trị trung bình khi **X** = 0.\n",
    "-\tB (**Slope/ Coefficient**): độ dốc, khi **X** thay đổi một $\\Delta X$ thì giá trị kỳ vọng của **Y** sẽ là $\\Delta Y = b \\cdot \\Delta X$ </br>\n",
    "**Giả sử**: Dự đoán điểm thi **Y** = 40 + 5*(giờ học) </br>\n",
    "$A$ = 40: Nếu giờ học = 0 thì điểm dự đoán TB là 40 nhưng sẽ có sai số $\\varepsilon$.</br>\n",
    "$B$ = 5: Nếu tăng giờ học lên 1 giờ thì số điểm sẽ tăng 5; thêm 2 giờ học thì điểm tăng 10; tăng $k$ giờ  học thì điểm tăng 5k. </br>\n",
    "\n",
    "\n",
    "⇒ Nếu tồn tại $N$ input $X$ (**Multiple Linear Regression**): Dự đoán mức lương của một nhân viên dựa vào số năm kinh nghiệm của nhân viên và trình độ học vấn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5efaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3fb9fa0",
   "metadata": {},
   "source": [
    "![alt text](https://raw.githubusercontent.com/aquattda/LTT_Sklearn_ML/blob/main/images/Multiple_Linear.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3d154",
   "metadata": {},
   "source": [
    "### 2.\tPolynomial Regression (Đa thức)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c1445",
   "metadata": {},
   "source": [
    "- Đây được coi là bản cải tiến của linear do có sự xuất hiện của các phần tử bậc $1, 2, … N$. Sử dụng khi chúng ta muốn biết giá trị $N$ là bao nhiêu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e71e26",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/polynomial.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07958f23",
   "metadata": {},
   "source": [
    "So sánh Simple linear vs Polynomial Regresstion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03a93b",
   "metadata": {},
   "source": [
    "| Simple linear model | Polynomial model |\n",
    "|---|---|\n",
    "| • Chỉ số $X$ nằm ở dưới *(subscript)* giúp phân biệt các $x$ đầu vào khác nhau. | • Chỉ số $X$ ở phía trên *(superscript)* để nói về **bậc** của $x$ tương ứng. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71cabc7",
   "metadata": {},
   "source": [
    "#### 2.2 Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12223eca",
   "metadata": {},
   "source": [
    "-\tXảy ra khi độ phức tạp của mô hình > độ phức tạp của dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261faf5d",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2efc9",
   "metadata": {},
   "source": [
    "Trong sơ đồ này:\n",
    "- Có **6 data points** được huấn luyện bởi **2 mô hình Polynomial** ($N=2$, $N=10$).\n",
    "  - Với **$N=2$** *(đường vàng)*: sai số ở mức **chấp nhận được**.\n",
    "  - Với **$N=10$** *(đường đỏ)*: sai số **train** thấp hơn $N=2$, nhưng khi thêm dữ liệu mới/suy rộng ra **test**, sai số **tăng** (tức khả năng khái quát kém).\n",
    "- **$N=10$** đại diện cho **hàm bậc cao** ⇒ mô hình **phức tạp**. </br>\n",
    "⟶ Đây là ví dụ điển hình của **Overfitting**.  \n",
    "⟶ **$N$ càng cao** ⇒ **train error** thường **thấp**, nhưng **test error** thường **cao**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb823e",
   "metadata": {},
   "source": [
    "**Giả sử:** Ở kiểm tra giữa kỳ, sinh viên “học vẹt” đạt điểm rất cao vì cấu trúc bài không đổi.  \n",
    "Đến **cuối kỳ**, cấu trúc/bậc phức tạp **thay đổi** ⇒ điểm **giảm**.\n",
    "\n",
    "⟶ Đây là ví dụ điển hình của **overfitting**: học thuộc “đề cũ” nhưng **khái quát hoá** kém trên đề mới.\n",
    "\n",
    "⟶ Khi triển khai, cần **tối thiểu hoá sai số** giữa dự đoán và thực tế **đồng thời** **kiểm soát độ phức tạp mô hình** ⇒ **Regularization (Điều chuẩn)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65feca",
   "metadata": {},
   "source": [
    "#### 2.3. Regularization cơ bản:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315bb1f3",
   "metadata": {},
   "source": [
    "##### 2.3.1. Kỹ thuật 1 **(Lasso)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3914af3",
   "metadata": {},
   "source": [
    "- Thành phần **Regulaziation** của trọng số Wj được tính bằng tổng giá trị tuyệt đối."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2cf45",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cost}_{\\mathrm{L1}}\n",
    "= \\sum_{i=0}^{N}\\!\\left(y_i-\\sum_{j=0}^{M} x_{ij} W_j\\right)^2\n",
    "+ \\lambda \\sum_{j=0}^{M} \\lvert W_j\\rvert\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa309579",
   "metadata": {},
   "source": [
    "**So sánh Normal & Lasso:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065c7f1",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d156cc5",
   "metadata": {},
   "source": [
    "- **Biểu đồ bên trái (chưa Regularization):**\n",
    "  - Độ dài đoạn thẳng tỉ lệ với $W_i$. Đoạn càng dài ⇒ feature $X_i$ ảnh hưởng càng mạnh đến output.\n",
    "\n",
    "- **Biểu đồ bên phải (đã Regularization):**\n",
    "  - Trọng số bị **thu nhỏ** về gần 0; một số **bị ép đúng 0** (ví dụ $j=0$ và $j=5$) ⇒ các feature tương ứng **không còn ảnh hưởng** đến output.\n",
    "\n",
    "- **Kết luận:** **LASSO (L1)** hay dùng cho **Feature Selection** vì có thể làm nhiều $W_i=0$;  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f7390",
   "metadata": {},
   "source": [
    "##### 2.3.2. Kỹ thuật 2 **(Ridge)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870d61f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "- Thành phần regura của trọng số Wj được tính bằng tổng bình phương."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3fdbd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cost}_{\\mathrm{L2}}\n",
    "= \\sum_{i=0}^{N}\\!\\left(y_i-\\sum_{j=0}^{M} x_{ij} W_j\\right)^2\n",
    "+ \\lambda \\sum_{j=0}^{M} W_j^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e7156",
   "metadata": {},
   "source": [
    "**So sánh Normal & Ridge:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc166e8",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e3624",
   "metadata": {},
   "source": [
    "-\tĐối với ridge thì nó sẽ giảm độ ảnh hưởng của toàn bộ các feature chứ không “ép” như lasso </br>\n",
    "⟶ Trong ML ta có thể áp dụng các kỹ thuật regularization trong nhiều bài toán khác nhau kể cả bài toán regression, classification\n",
    "\n",
    "- **Đối với Ridge (L2)**: giảm (shrink) **độ lớn của tất cả hệ số** → hiếm khi bằng 0. </br>\n",
    "⟶ Trong ML, **regularization** được áp dụng rộng rãi cho cả **regression** lẫn **classification** để kiểm soát độ phức tạp và giảm overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f087ab",
   "metadata": {},
   "source": [
    "##### 2.3.3. Kỹ thuật 3 **(Elastic Net)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ed0bb",
   "metadata": {},
   "source": [
    "- Sự kết hợp giữa L1 & L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b3672",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c170fc3",
   "metadata": {},
   "source": [
    "**Tình huống:** Tập trainning $Y$ có giá trị [$-∞, +∞$], và nó phục vụ cho bài toán Linear. Vậy nếu ta muốn áp dụng thuật toán này vô **Classification (Binary Classification)** và nó có giá trị output [$0, 1$]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcad75",
   "metadata": {},
   "source": [
    "### 3.\tLogistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac09749",
   "metadata": {},
   "source": [
    "-\tÝ tưởng của bài toán này là thực hiện việc ánh xạ Y sao cho nó nằm trong khoảng [$0, 1$]. Sau đó đặt một giá trị ngưỡng ($p$). Nếu các giá trị output $> p$ thì sẽ ở class số 1 và output $< p$ sẽ ở class 0. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186597b",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da47df",
   "metadata": {},
   "source": [
    "-\tThuật toán **Logistic Regression** dựa vào thuật toán **Linear Regression** tạo ra output và cho output đó đi qua **Sigmoid function**. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f41b47",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db303c",
   "metadata": {},
   "source": [
    "- Trong đó Z là input đầu vào có giá trị bất kỳ [$-∞, +∞$] ⇒ output có giá trị ($0,1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec3c27",
   "metadata": {},
   "source": [
    "-\tDo ý tưởng của thuật toán **Logistic regression** áp dụng giải thuật **Linear regression** mà thuật toán **Linear regression** là một hàm bậc 1 ($ax + b$) cho nên đối với **Logistic Regression* thì $Z$ sẽ thay đổi theo. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da67428",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d68c5f",
   "metadata": {},
   "source": [
    "- Thứ tự thực hiện:\n",
    "    -\tĐầu tiên sẽ chạy thuật toán **Linear regression** sau đó tìm ra được các output.\n",
    "    -\tLấy các output đó sử dụng **Sigmoid function** tạo ra output mới là $0.85$.\n",
    "    -\tSử dụng **Logistic regression** so sánh giá trị output mới đi so sánh với giá trị ngưỡng ($0.5$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdb3b9",
   "metadata": {},
   "source": [
    "- **LƯU Ý:**\n",
    "    -\tTuy thuật toán **Logistic Regression** có chữ **Regression** nhưng đây là thuật toán để thực hiện bài toán **classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8393be",
   "metadata": {},
   "source": [
    "- **Trong Sklearn:**\n",
    "    -\tNếu muốn kết hợp logistic regression với các kỹ thuật **Regularzation (Lasso, Ridge, Elastic Net)* => sử dụng tham số *(penalty{‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’)* </br>\n",
    "\n",
    "⇒ Giải quyết bài toán **Classification (Binary Classification)* khi chỉ có 2 class nhưng target [$0, 1$]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cef7ff",
   "metadata": {},
   "source": [
    "**Tình huống:** Vậy nếu bài toán **Classification** có nhiều hơn 2 class thì sao?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c8da5",
   "metadata": {},
   "source": [
    "#### 3.1.\tMultinomial Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055613e2",
   "metadata": {},
   "source": [
    "- Giống như **Linear** thì Logistic cũng có **Multinomia** để giải quyết các bài tonas **Classification** có nhiều hơn 2 class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201ef7e",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75a5bd",
   "metadata": {},
   "source": [
    "-\tĐối với **Multinomial Logistic Regression** nó sẽ sử dụng thuật toán **Softmax Activation Function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb763228",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d1f1c",
   "metadata": {},
   "source": [
    "-\tThuật toán này sẽ ánh xạ các dữ liệu là một vector có giá trị [$-∞, +∞$] ⇒ Các vector có giá trị [$0, 1$], cuối cùng sẽ chọn **Max Value** làm phần tử cuối </br>\n",
    "\n",
    "⇒ Dựa vào đó nên thuật toán này thường sử dụng giải thích xác xuất và dự đoán dành cho từng class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccf1b8",
   "metadata": {},
   "source": [
    "- **Trong Sklearn:**\n",
    "    -\tKhi sử dụng model **LogisticRegression** nếu có nhiều hơn 2 class thì sẽ tự chuyển đổi thành **Multinomial Logistic Regresstion** \n",
    "    (use **OneVsRestClassifier**)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0f626",
   "metadata": {},
   "source": [
    "### 4. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e8ce8",
   "metadata": {},
   "source": [
    "#### 4.1. Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c93cc4",
   "metadata": {},
   "source": [
    "- Trong lý thuyết xác suất định lý **Bayes Theorem** là một định lý áp dụng rộng rãi trong DS , ML. Giúp ta tính được xác suất xảy ra ở một sự kiện nào đó, mà biết được một sự kiện khác đã xảy ra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52c2f6",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84acf1eb",
   "metadata": {},
   "source": [
    "**Tình Huống:**\n",
    "- Nếu có một text và cần kiểm tra xem xác suất của đoạn text đó thuộc loại nào."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bbe97",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b46a8b",
   "metadata": {},
   "source": [
    "- Trong ảnh, cần kiểm tra xem đoạn text thuộc loại Positive hay Negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d6972",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6aa8e",
   "metadata": {},
   "source": [
    "-\tVề bản chất thì đoạn text sẽ là các từ riêng lẻ, cho nên cần kiểm tra tỷ lệ % của các từ đó. Rõ ràng chúng ta cần tính một xác suất có điều kiện cho nên dựa vào định lý **Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f53d5f",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc5c92",
   "metadata": {},
   "source": [
    "-\tKhi áp dụng đính lý vào thì sẽ xảy ra vấn đề rằng 3 phép tính đằng sau sẽ phức tạp cho nên cần áp dụng thêm một giả thuyết."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e30730",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1885b6c",
   "metadata": {},
   "source": [
    "-\tGiả thuyết cho rằng nếu các từ được phân chia ở các class riêng biệt thì xác suất của các từ xuất hiện là độc lập với nhau. Nhưng trong thực tế, việc chia các từ độc lập là không hợp lý vì các từ xuất hiện sẽ có mối liên hệ với nhau. Tuy nhiên việc áp dụng giả thuyết này chỉ mang tính chất giúp giải quyết bài toán trở nên dễ dàng hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbd01f",
   "metadata": {},
   "source": [
    "#### 4.2. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24b77d",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c364a",
   "metadata": {},
   "source": [
    "##### 4.2.1. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504476da",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f462aea",
   "metadata": {},
   "source": [
    "-\tNếu input đầu vào là các biến rời rạc và giá trị được xác định bằng **số lần xuất hiện trong đoạn text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0378cd",
   "metadata": {},
   "source": [
    "##### 4.2.2. Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436a8e0",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79165f8",
   "metadata": {},
   "source": [
    "-\tNếu input đầu vào là các biến rời rạc và giá trị được xác định bằng **chúng có xuất hiện hay không trong đoạn text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07521458",
   "metadata": {},
   "source": [
    "##### 4.2.3. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb83655",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd75c2",
   "metadata": {},
   "source": [
    "-\tNếu input đầu vào là biến liên tục và có thêm giả thuyết về Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636441b",
   "metadata": {},
   "source": [
    "**TÌNH HUỐNG:** Ta đã học các thuật toán về hồi quy và phân loại bây giờ ta sẽ học các thuật toán áp dụng cho cả 2 thuật toán này"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4646ee4",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9c72f",
   "metadata": {},
   "source": [
    "-\tMở đầu là một thuật toán dễ giải thích và trực quan nhất trong ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0868048",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc4ae3",
   "metadata": {},
   "source": [
    "**Giả sử:** Áp dụng thuật toán giải quyết bài toán tuyển nhân viên."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f7f0b",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d68dfc",
   "metadata": {},
   "source": [
    "- Dựa vào độ lệch của các leaf node để xác định, nếu độ lệch tương đối cần phải phân nhánh tiếp. Ngược lại, ta dựa vào đó mà đưa ra quyết định. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d0ef7",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th colspan=\"2\" style=\"text-align:center\">Độ lệch lớn</th>\n",
    "      <th colspan=\"2\" style=\"text-align:center\">Độ lệch nhỏ</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"text-align:center\"><b>80, 20</b></td>\n",
    "      <td style=\"text-align:center\"><b>50, 250</b></td>\n",
    "      <td style=\"text-align:center\"><b>120, 80</b></td>\n",
    "      <td style=\"text-align:center\"><b>100, 200</b></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d0515",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "**Tình Huống:** Trong thực tế, việc phân chia này phụ thuộc vào việc phân chia các feature phù hợp để tối ưu level của cây và độ lệch lớn nhất. Có rất nhiều cách để giúp ta xác định được việc lựa chọn các feature phù hợp. Một trong những cách phổ biến là dựa vào **Gini Impurity** và **Information Gain (Entropy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cdbc2",
   "metadata": {},
   "source": [
    "#### 5.1. Gini Inpurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb9c75",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454b6f1",
   "metadata": {},
   "source": [
    "Trong đó:\n",
    "-\tC: là tổng số lượng class trong Target\n",
    "-\tPi là xác suất của một phần tử thuộc về class i\n",
    "\n",
    "Trường hợp:\n",
    "- Gini [$0, 0.5$] => Feature làm cho leaf node bị phân chia cao (độ lệch lớn)\n",
    "- Gini [$> 0.5$] => Feature làm cho leaf node bị phân chia thấp (độ lệch nhỏ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5207f5",
   "metadata": {},
   "source": [
    "**Giả sử:** Áp dụng thuật toán giải quyết bài toán cho vay ngân hàng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ca793",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bd200",
   "metadata": {},
   "source": [
    " - Đối với Age[Youth]: \n",
    "    - Yes(2) ~ Pi = 0.4\n",
    "    - No(3) ~ Pi = 0.6 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc693a",
   "metadata": {},
   "source": [
    "- Sau khi có Gini ta cần tính Mean của các Gini đó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933bb90",
   "metadata": {},
   "source": [
    "=> Các Mean(Gini) thấp nhất sẽ chọn best feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79723014",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f3a9e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ccb4f1",
   "metadata": {},
   "source": [
    "#### 5.2. Infomation Gain (Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14365d7",
   "metadata": {},
   "source": [
    "- Đây là một chỉ số khác để xác định các best decision node.\n",
    "- Thực hiện việc tìm các ngưỡng tách (trên feature) làm sao cho độ hỗn tạp của nhãn sau khi tách giảm nhiều nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c3347",
   "metadata": {},
   "source": [
    "- Công thức markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b5053",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2643778",
   "metadata": {},
   "source": [
    "**Nhược điểm:** \n",
    "- Dễ bị **Overfitting** ( đặc biệt là cây quá nhiều bậc)\t \n",
    "- Chỉ một thay đổi nhỏ của dữ liệu sẽ ảnh hưởng lớn đến cấu trúc của toàn bộ cây.\n",
    "- Tuy **Desition Tree** có thể sử dụng cho **Regresstion or Classification** nhưng trong thực tế không nên sử dụng với **Regresstion** vì rất khó để tìm được khoảng cách TB đối với **Overfitting** và **Underfitting**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8585300",
   "metadata": {},
   "source": [
    "#### 5.3. Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8a83e",
   "metadata": {},
   "source": [
    "-\tĐây là hiện tượng đối lập với **Overfitting**. Tức là độ phức tạp của dữ liệu > mô hình </br>\n",
    "=> Mô hình không đủ để tổng quát hóa xu hướng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b75f3",
   "metadata": {},
   "source": [
    "**Tình Huống:**\n",
    "-\tViệc sử dụng **Decision Tree** một mình khiến độ chính xác không cao, nên cần kết hợp nhiều **Decision Tree** lại với nhau để gia tăng độ chính xác\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da334dff",
   "metadata": {},
   "source": [
    "### 6. Random Forest (Dừng ngẫu nhiên)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f254e5",
   "metadata": {},
   "source": [
    "#### 6.1. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355754fc",
   "metadata": {},
   "source": [
    "- Đối với bài toán **Classification** thì cách thức kết hợp là sử dụng **Majority vote**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603c31a",
   "metadata": {},
   "source": [
    "##### 6.1.1. Majority Vote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca702d08",
   "metadata": {},
   "source": [
    "- Các vote nhiều nhất của từng **Decision** sẽ được chọn vào **Final Prediction** (Dự đoán cuối)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465e585",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd020b98",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16ce12ee",
   "metadata": {},
   "source": [
    "**Giả Sử:** Ứng dụng vào bài toán phân loại chó, mèo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7184cc",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844bc2d",
   "metadata": {},
   "source": [
    "#### 6.2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36edfdb",
   "metadata": {},
   "source": [
    "- Đối với bài toán **Regression** thì sẽ sử dụng **Averaging**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cbc05",
   "metadata": {},
   "source": [
    "##### 6.2.1. Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13afecca",
   "metadata": {},
   "source": [
    "- Lấy giá trị trung bình của các Decision Tree sẽ được cho vào **Final Prediction** (Dự đoán cuối)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5252fbf",
   "metadata": {},
   "source": [
    "**Giả Sử:** Ứng dụng vào bài toán mật độ ảnh hưởng ABC.="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061267f4",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13c8ef",
   "metadata": {},
   "source": [
    "**LƯU Ý:**\n",
    "-\tNếu chỉ training trên một bộ dữ liệu thì dự đoán sẽ giống nhau, cho nên để **Random Forest** có ý nghĩa thì mỗi **Decision Tree** cần phải training các bộ dữ liệu khác nhau để đa dạng kết quả trả về.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af91bd0",
   "metadata": {},
   "source": [
    "**TÌNH HUỐNG:** Vậy làm thế nào để training các bộ dữ liệu khác nhau?|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6491218",
   "metadata": {},
   "source": [
    "#### 6.1. Boostrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239d910",
   "metadata": {},
   "source": [
    "-\tĐây là kỹ thuật lấy từ mẫu gốc ban đầu sẽ lấy mẫu còn lại nhiều lần để tạo ra nhiều bộ dữ liệu con khác nhau, mỗi Subset sẽ được huấn luyện cho từng Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15260994",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961f1ba",
   "metadata": {},
   "source": [
    "**GIẢ SỬ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc25605",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60dba8",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "Bảng so sánh Decision Tree & Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a177b4c",
   "metadata": {},
   "source": [
    "| **Tiêu chí** | **Decision Tree (DT)** | **Random Forest (RF)** |\n",
    "|---|---|---|\n",
    "| **Chọn feature ở mỗi node** | Chọn **best** trong **tất cả** feature. | Chọn **best** trong **tập con ngẫu nhiên** các feature. |\n",
    "| **Ví dụ minh hoạ** | Best trong **4** feature. | Best trong **3** feature ngẫu nhiên (từ **4**). |\n",
    "| **Mục đích/hiệu ứng** | — | **Tăng đa dạng** giữa các cây & dự đoán. |\n",
    "| **Overfitting** | — | **Ít bị overfitting hơn.** |\n",
    "| **Độ chính xác thực tế** | — | **Cao hơn DT**, được nhiều người ưa chuộng. |\n",
    "| **Mức độ giải thích** | **Cao** (dễ truy vết đường đi từ Root node → leaf node). | **Thấp hơn DT**; sau khi có dự đoán cuối vẫn có thể giải thích nhưng khó khăn. |\n",
    "| **Tài nguyên & thời gian** | — | **Tiêu tốn hơn DT** (tài nguyên & thời gian). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f96aa",
   "metadata": {},
   "source": [
    "## 7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87af9e",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "-\tĐây là một thuật toán phức tạp trong Basic ML.\n",
    "-\tMục tiêu cho bài toán Classification là tìm ra một đường phân cách tốt nhất để phân chia các điểm dữ liệu thuộc về các class khác nhau trong không gian đa chiều </br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd96ace",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76dfb8a",
   "metadata": {},
   "source": [
    "-\tTrong ảnh là Binary Classification đối với 2 class (Tròn, Sao) trong không gian 2 chiều. \n",
    "- Đường màu hồng là đường phân cách tối ưu vì nó thỏa 2 điều kiện:\n",
    "    - cách đều margin (lề) của 2 class.\n",
    "    - margin của đường phân cách tối ưu này tạo ra là tối đa.\n",
    "-\tTrong SVM thì các điểm thuộc các class gần với đường tối ưu nhất gọi là Support vector, vì chúng sẽ xác định công thức.\n",
    "\n",
    "⟶ Các đường phân cách (**Hyperplane**) và đường phân cách tối ưu (**Optimal hyperplane**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0764a9",
   "metadata": {},
   "source": [
    "Giả sử: Đối với trong ảnh là vector 2 chiều ($y= ax+b$) thì các điểm này sẽ quyết định a và b là bao nhiêu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f1d8f",
   "metadata": {},
   "source": [
    "**LƯU Ý:** Trong dữ liệu thực tế thì có 2 tình huống mà SVM phải đổi mặt.\n",
    "-\tKhông phải lúc nào SVM cũng tìm đường phân cách tối ưu để phân chia hoàn toàn các điểm dữ liệu mà không sai sót.\n",
    "\n",
    "⟶ Thiết lập giá trị **Hyperparameter(C)** sẽ đặt một ngưỡng chấp nhận sai sót nếu thỏa dưới ngưỡng\n",
    "-\tKhông phải lúc nào dữ liệu cũng phân chia tuyến tính. Giả sử vector 2 chiều, thì không phải lúc nào cũng tìm đường một đường thẳng để phân chia các điểm dữ liệu\n",
    "\n",
    "⟶ Áp dụng kỹ thuật **Kernel Trick** sẽ đưa dữ liệu từ không gian ít chiều sang không gian nhiều chiều, giúp phân chia dễ dàng hơn một cách tuyến tính\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f9bbb",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953ede0",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "LƯU Ý:\n",
    "-\tHyperplane (Siêu phẳng): Tùy thuộc vào không gian thì Hypterplane sẽ có hình dạng khác nhau.\n",
    "    - Đối với không gian 2 chiều: Đường thẳng\n",
    "    - Đối với không gian 3 chiều: Mặt phẳng\n",
    "    \n",
    "⟶ Số chiều của Hyperplane < số chiều không gian + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151ebea",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "**ƯU ĐIỂM:**\n",
    "-\tCó performance cao và làm việc tốt với dữ liệu nhiều chiều. Bản thân SVM đã đưa dữ liệu ít chiều sang không gian nhiều chiều\n",
    "\n",
    "**NHƯỢC ĐIỂM:**\n",
    "-\tNếu dữ liệu có quá nhiều data point thì sẽ phức tạp khi sử dụng\n",
    "\n",
    "**TRONG SKLEAR:**\n",
    "-\tSẽ có Class dành cho 2 bài toán sklearn.svm.SVC và  sklearn.svm.SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed45ba",
   "metadata": {},
   "source": [
    "**TÌNH HUỐNG:** Vậy Kernel Trick là gì? Làm thế nào mà có thể thay đổi chiều không gian của dữ liệu.  Lý do sau khi sử dụng Kernel Trick thì lại dễ dàng phân chia dữ liệu tuyến tính \n",
    "\n",
    "TỰ TÌM HIỂU HOẶC TÌM XEM CÓ  VIDEO HƯỚNG DẪN \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be174e",
   "metadata": {},
   "source": [
    "**All algorithms until now:** Các thuật toán từ trước đến giờ đều tuân theo một motip chung (model  ML, dataset nhằm tìm ra một đường phân cách giúp chia các data point về các class khác nhau) đường phân cách (hyperplane) sẽ có hình dạng khác nhau tùy thuộc vào ML.\n",
    "\n",
    "-> Tìm được công thức của hyperplane và trong tương lai sẽ sử dụng hyperplane để dự đoán các class cho data point (chưa thấy bao giờ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302554f",
   "metadata": {},
   "source": [
    "**TÌNH HUỐNG:** Vậy có thuật toán nào không cần thông qua training mà trực tiếp sử dụng data point vào quá trình dự đoán?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293f114",
   "metadata": {},
   "source": [
    "## 8. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d7b53",
   "metadata": {},
   "source": [
    "-\tKhông như các model ML khác, thuật toán này sử dụng trực tiếp data point trong dataset đi dự đoán các data point mới."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78dbdd",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0858591",
   "metadata": {},
   "source": [
    "**LƯU Ý:**\n",
    "-\tK quyết định “độ rộng lân cận”\n",
    "-\tViệc chọn K là số lẻ để tránh hòa (tie) khi bỏ phiếu\n",
    "    - K = 4 (even): 2-2  \n",
    "    - K = 3 (odd): 1-2, 2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9562",
   "metadata": {},
   "source": [
    "| **Overfitting (k = 1, 3, …)** | **Underfitting (k = 31, 53, …, N)** |\n",
    "|---|---|\n",
    "| Độ phức tạp cao, dựa vào ít điểm lân cận <br> ⇒ Nhiễu/Outlier ⇒ Test error tăng | Độ phức tạp nhỏ, lấy TB trên vùng rộng <br> ⇒ bias tăng ⇒ Test error cao |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac92cc",
   "metadata": {},
   "source": [
    "=> Nếu sử dụng trọng số khoảng cách (weights='distance') trong đa lớp hoặc dò K bằng cross-validation thì K even hay odd không còn quan trọng (giảm rủi ro tie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec6479",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/overfitting.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66a9e9",
   "metadata": {},
   "source": [
    "-\tSau khi xác định được K thì nếu data point đó thuộc nhiều phía class nào nhất thì nó sẽ là data point của class đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fd8fb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf1f0b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9408fb24",
   "metadata": {},
   "source": [
    "**LƯU Ý:**\n",
    "-\tTương tự như Decision tree thì KNN cần kết hợp nhiều data point lại để gia tăng độ chính xác và 2 bài toán Classification hay Regression thì đều sử dụng giống DT\n",
    "\n",
    "**NHƯỢC ĐIỂM:**\n",
    "-\tKhông ổn định, chậm đối với các dataset lớn có nhiều data point, tốn thời gian và tài nguyên khi tính toán.\n",
    "-> Vì mỗi data point cần phải tìm khoảng cách từ data point này với tất cả các data point trong data train\n",
    "\n",
    "**TRONG SKLEAR:**\n",
    "-\tSẽ có Class dành cho 2 bài toán sklearn.neighbors.KNeighborsClassifier và sklearn. neighbors.KneighborsRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ce45b",
   "metadata": {},
   "source": [
    "**TÌNH HUỐNG:** \n",
    "-\tCác thuật toán đều là thuật toán đơn lẻ, ngoại lệ là Random Forest dùng tổng hợp các Decision Tree lại với nhau.\n",
    "-\tViệc áp dụng các mô hình đơn giản có độ chính xác thấp thành mô hình phức tạp có độ chính xác cao \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe27a25",
   "metadata": {},
   "source": [
    "## II. Ensemble Learning (Tổng hợp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b5fcb",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/el.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1623e",
   "metadata": {},
   "source": [
    "### 1. Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9570e5",
   "metadata": {},
   "source": [
    "-\tHuấn luyện nhiều mô hình con khác và cùng loại (Weak models) (mô hình yếu), các model này có độ chính xác thấp và dễ overfitting\n",
    "-\tMỗi mô hình con sẽ được train bởi dữ liệu gốc thông qua phương pháp Bossshopping (lấy mẫu còn lại)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67425328",
   "metadata": {},
   "source": [
    "**LƯU Ý:**\n",
    "-\tĐối với Bagging nói riêng hay RF nói chung thì các Weak models bị overfitting trên dataset của chúng, hay nói cách khác là Low Bias và Hight Variance là điều bình thường.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6fc8b",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/aquattda/LTT_Sklearn_ML/blob/main/images/bagging.png) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f1ee5",
   "metadata": {},
   "source": [
    "### 2. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd33cc2",
   "metadata": {},
   "source": [
    "- NÀY TÍ VỀ LÀM TABE SO SÁNH SẼ HAY HƠN \t\n",
    "\n",
    "- Nếu trong Bagging huấn luyện các mô hình con song song thì đối với Bagging sẽ huấn luyện theo tuần tự và được huấn luyện trên toàn bộ tập dữ liệu.\n",
    "-\tTrongg  Boosting thì mô hình đầu tiên sẽ được huấn luyện trên toàn bộ tập dữ liệu sau đó sẽ đưa ra dự đoán cho từng data point một, tiếp đến mô hình 2 sẽ  cũng áp dụng trên toàn bộ tập dữ liệu nhưng tập trung đối với các data point sai, áp dụng tuần tự đến mô hình cuối cùng.\n",
    "-\tCác mô hình sau sẽ gắn trọng số cao hơn với các data point mà mô hình trước dự đoán sai và ngược lại. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c09d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f61d15",
   "metadata": {},
   "source": [
    "| **Bagging** | **Boosting** |\n",
    "|---|---|\n",
    "| Averaging (**mean không trọng số**) nên các mô hình con **bình đẳng** với nhau để đưa ra dự đoán cuối. | Averaging (**mean có trọng số**) nên các mô hình con có **trọng số/tầm quan trọng khác nhau** để đưa ra dự đoán cuối. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112fe7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8e11b27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36731fc2",
   "metadata": {},
   "source": [
    "| **Đặc điểm** | **Bagging** | **Voting** |\n",
    "|---|---|---|\n",
    "| **Giống** | Tập hợp huấn luyện các mô hình con **song song**. | Tập hợp huấn luyện các mô hình con **song song**. |\n",
    "| **Khác (1)** | Các mô hình con **cùng một loại** (ví dụ: đều là DT). | Các mô hình con **khác loại** (LG, DT, SVM, …). |\n",
    "| **Khác (2)** | Các mô hình con được huấn luyện bởi **các subset khác nhau** của dữ liệu. | Tất cả mô hình con huấn luyện trên **cùng dataset gốc** *(tương đương boosting về dữ liệu, không bootstrap)*. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98f38d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
